{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0e1c01-6951-46a1-9cea-f957db770c44",
   "metadata": {},
   "source": [
    "By: David Plehn and Anika Achary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba03509-3468-4df7-9f02-11994abe7b97",
   "metadata": {},
   "source": [
    "Link to UCI data repository where data was acquired:\n",
    "https://archive.ics.uci.edu/dataset/186/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdcf3f-63a7-4510-8710-ad50ca4a04bd",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e88ae6-4287-43e0-be7d-45fc072e145e",
   "metadata": {},
   "source": [
    "Problem:\n",
    "We will be creating a multinomial logistic regession model to predict wine quality (red and white variants of the Portuguese \"Vinho Verde\" wine) based on physicochemical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32968353-31f0-4080-a64b-8caba6e90772",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf97c44-0f1f-49cb-b960-79968b052ea6",
   "metadata": {},
   "source": [
    "Python Modules:\n",
    "*   Pandas\n",
    "*   Numpy\n",
    "*   matplotlib\n",
    "*   (%matplotlib inline to ensure it is properly displayed)\n",
    "*   sklearn\n",
    "*   seaborn\n",
    "*   scipy\n",
    "*   warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3a6987b-0b9a-47f2-88ac-32efc469c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fec062-70a6-484d-8e35-c9831a2efa90",
   "metadata": {},
   "source": [
    "Before we uploaded the dataset, we had to split the dataset by delimeter in excel so we could read it by columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e087a838-d88c-4966-8995-e9ae56920696",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/david/OneDrive/Desktop/Intro To ML/Final_Project/winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_red \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/david/OneDrive/Desktop/Intro To ML/Final_Project/winequality-red.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df_red\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/david/OneDrive/Desktop/Intro To ML/Final_Project/winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "df_red = pd.read_csv(\"C:/Users/david/OneDrive/Desktop/Intro To ML/Final_Project/winequality-red.csv\")\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e72072-d292-4940-b5bc-2624dfe12c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_white = pd.read_csv(\"C:/Users/david/OneDrive/Desktop/Intro To ML/Final_Project/winequality-white.csv\")\n",
    "df_white.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00535159-f882-4bd9-bb78-21a0c301cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_white.shape)\n",
    "print(df_red.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e91b34-5512-4c6c-a5a0-af4f2f98a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_white.info())\n",
    "print(\"-----------------------------------------\")\n",
    "print(df_red.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03afcc-132f-47eb-a07f-ccab6ec93ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_white.isnull().sum())\n",
    "print(\"-------------------\")\n",
    "print(df_red.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c0edb-a6b8-4cfe-a302-fe9374d70412",
   "metadata": {},
   "source": [
    "## Histograms on DataFrame features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f7bc0-9052-4440-b15e-8b21e110eef0",
   "metadata": {},
   "source": [
    "### Histograms for df_red's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a91be3d-bc57-46e5-9850-f89190ed8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red.hist(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747b18c-7239-400c-9518-b8888b9f6521",
   "metadata": {},
   "source": [
    "### Histograms for df_white's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7cec16-a9f7-4843-b6f9-38f7ab0b1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_white.hist(figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5141f-4208-4645-9cd1-8be8c3fa6948",
   "metadata": {},
   "source": [
    "## Pairplots on DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff1985b-1f1b-4e5c-beb9-b90390af620e",
   "metadata": {},
   "source": [
    "### Pairplot for df_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42eec7-ce3e-4a7e-9e7b-1cd8c597641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.pairplot(df_white)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fe533-93cc-4de8-b72e-5be8b4ff4197",
   "metadata": {},
   "source": [
    "### Pairplot for df_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eae0c6-e725-4827-ba76-3387644e753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_red)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe69778-2892-415d-901c-ffffe3b5d11c",
   "metadata": {},
   "source": [
    "## Correlation and heatmaps for DateFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4419f-daa1-4cc9-a723-a355adf01c33",
   "metadata": {},
   "source": [
    "### Correlation and heatmap for the df_red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc932c-4bd9-4ecf-a84f-16e7c97ece4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_red = np.triu(df_red.corr())\n",
    "ax_red = sns.heatmap(df_red.corr(), annot = True, square=True, \\\n",
    "            linewidths=1, linecolor='black') #, mask=matrix)\n",
    "bottom_red, top_red = ax_red.get_ylim()\n",
    "ax_red.set_ylim(bottom_red + 0.5, top_red - 0.5)\n",
    "df_red.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8473d93-aeb0-4388-8873-8872945865d6",
   "metadata": {},
   "source": [
    "### Correlation and heatmap for the df_white dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4b832-0a9f-4bfe-b234-ce30f152b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_white = np.triu(df_white.corr())\n",
    "ax_white = sns.heatmap(df_white.corr(), annot = True, square=True, \\\n",
    "            linewidths=1, linecolor='black') #, mask=matrix)\n",
    "bottom_white, top_white = ax_white.get_ylim()\n",
    "ax_white.set_ylim(bottom_white + 0.5, top_white - 0.5)\n",
    "df_white.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53395555-69bf-4677-a154-bc7545b19a7b",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04998476-8d0c-4ebd-9d44-d3590b1650ec",
   "metadata": {},
   "source": [
    "#### The lbfgs solver can account for multinomial loss, so we dont have to alter it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1da4bc-6c46-49f1-a2ec-c2d2cd23ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg_red = LogisticRegression(penalty='l2', C=1, solver='lbfgs', max_iter = 1000)\n",
    "reg_white = LogisticRegression(penalty='l2', C=1, solver='lbfgs', max_iter = 1000)\n",
    "print(reg_red)\n",
    "print(reg_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcad7f7-5222-425c-8a9d-fceabb6be7dd",
   "metadata": {},
   "source": [
    "### K^2 test for Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a99a9-6eb8-450b-9b40-c0bc248e07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "normal_features_red = []\n",
    "non_normal_features_red = []\n",
    "\n",
    "for feature in df_red:\n",
    "    stat, p = kstest(df_red[feature], 'norm', args=(df_red[feature].mean(), df_red[feature].std()))\n",
    "    if p > 0.05:\n",
    "        normal_features_red.append(feature)\n",
    "    else:\n",
    "        non_normal_features_red.append(feature)\n",
    "\n",
    "normal_features_white = []\n",
    "non_normal_features_white = []\n",
    "\n",
    "for feature in df_white:\n",
    "    stat, p = kstest(df_white[feature], 'norm', args=(df_white[feature].mean(), df_white[feature].std()))\n",
    "    if p > 0.05:\n",
    "        normal_features_white.append(feature)\n",
    "    else:\n",
    "        non_normal_features_white.append(feature)\n",
    "\n",
    "print(\"Normally Distributed Features for df_red:\", normal_features_red)\n",
    "print(\"Non-Normally Distributed Features for df_red:\", non_normal_features_red)\n",
    "print(\"---------------------------------------------------------------------------------------\")\n",
    "print(\"Normally Distributed Features for df_white:\", normal_features_white)\n",
    "print(\"Non-Normally Distributed Features for df_white:\", non_normal_features_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019bf616-7f23-4c58-8938-d08ab280b9c2",
   "metadata": {},
   "source": [
    "### QuantileTransformer on Non-Normally Distributed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed99c6a-d9b3-4f99-85af-66fdb15fad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "df_red_independent = quantile_transformer.fit_transform(df_red[['fixed acidity', 'volatile acidity', 'chlorides', 'total sulfur dioxide', 'density', 'alcohol']])\n",
    "df_white_independent = quantile_transformer.fit_transform(df_white[['fixed acidity', 'volatile acidity', 'chlorides', 'total sulfur dioxide', 'density', 'alcohol']])\n",
    "\n",
    "# after scaling\n",
    "df_red_independent[0:5]\n",
    "df_white_independent[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b77195-a263-4fc1-9430-409c1ba89fc6",
   "metadata": {},
   "source": [
    "### Training the models and predicting their values and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d7547-5a0c-4956-bfde-069f22dd316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_red_train, x_red_test, y_red_train, y_red_test = train_test_split(df_red_independent, df_red[\"quality\"], test_size=0.2, random_state=4)\n",
    "reg_red.fit(x_red_train, y_red_train)\n",
    "\n",
    "print(reg_red.coef_) \n",
    "print(reg_red.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a9858-95a4-4448-a547-b1e3ecd43397",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_white_train, x_white_test, y_white_train, y_white_test = train_test_split(df_white_independent, df_white[\"quality\"], test_size=0.2, random_state=4)\n",
    "reg_white.fit(x_white_train, y_white_train)\n",
    "\n",
    "print(reg_white.coef_) \n",
    "print(reg_white.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9d2b5-5c6a-496d-9f38-faf6c2e6bdaa",
   "metadata": {},
   "source": [
    "### Predicting Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fe459-27c0-4238-b215-8df6dd5a3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_red = reg_red.predict(x_red_test) \n",
    "y_red_score = reg_red.predict_proba(x_red_test)\n",
    "\n",
    "yhat_white = reg_white.predict(x_white_test) \n",
    "y_white_score = reg_white.predict_proba(x_white_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fe6684-527e-4d65-afec-4c6019337d87",
   "metadata": {},
   "source": [
    "### Testing Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bb816-8349-42e7-a096-aefcd25fee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Base rate accuracy for red is: %0.2f\" %(accuracy_score(y_red_test, yhat_red)))\n",
    "print(\"Base rate accuracy for white is: %0.2f\" %(accuracy_score(y_white_test, yhat_white)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf2894-40b4-4938-a7b6-e022ab313450",
   "metadata": {},
   "source": [
    "### Transforming the test data for use in multinomial logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f75395-a2fa-4753-a196-b403bdcd5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer_red = LabelBinarizer().fit(y_red_train)\n",
    "y_red_onehot_test = label_binarizer.transform(y_red_test)\n",
    "\n",
    "label_binarizer_white = LabelBinarizer().fit(y_white_train)\n",
    "y_white_onehot_test = label_binarizer_white.transform(y_white_test)\n",
    "\n",
    "target_names = df_red[\"quality\"].unique()\n",
    "n_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f7bfb-671f-412a-b4b7-587dacaae3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_names)\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00672f30-5d76-4ac8-bef9-a3217cb039fb",
   "metadata": {},
   "source": [
    "## Computing Micro and Macro averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249a9a07-515c-4fb0-8449-a09eee79fb21",
   "metadata": {},
   "source": [
    "### Computing the Micro-averaged One-vs-Rest ROC AUC score for red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a5225-4365-4998-bad9-6bacbcbd0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr_red, tpr_red, roc_auc_red = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_red[\"micro\"], tpr_red[\"micro\"], _ = roc_curve(y_red_onehot_test.ravel(), y_red_score.ravel())\n",
    "roc_auc_red[\"micro\"] = auc(fpr_red[\"micro\"], tpr_red[\"micro\"])\n",
    "\n",
    "print(f\"Micro-averaged One-vs-Rest ROC AUC score for red wine:\\n{roc_auc_red['micro']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1040a-c386-4100-85cb-b0c29e22dab0",
   "metadata": {},
   "source": [
    "### Computing the Macro-averaged One-vs-Rest ROC AUC score for red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3a640-e280-43d5-a27f-7c6ee3ebfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    fpr_red[i], tpr_red[i], _ = roc_curve(y_red_onehot_test[:, i], y_red_score[:, i])\n",
    "    roc_auc_red[i] = auc(fpr_red[i], tpr_red[i])\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "# Interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(fpr_grid, fpr_red[i], tpr_red[i])  # linear interpolation\n",
    "\n",
    "# Average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr_red[\"macro\"] = fpr_grid\n",
    "tpr_red[\"macro\"] = mean_tpr\n",
    "roc_auc_red[\"macro\"] = auc(fpr_red[\"macro\"], tpr_red[\"macro\"])\n",
    "\n",
    "print(f\"Macro-averaged One-vs-Rest ROC AUC score for red wine:\\n{roc_auc_red['macro']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0dc98-645f-45f4-a55c-1ea99fb3330e",
   "metadata": {},
   "source": [
    "### Computing the Micro-averaged One-vs-Rest ROC AUC score for white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929c0ea-78d0-4bee-8d74-4f2d0d8e3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr_white, tpr_white, roc_auc_white = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr_white[\"micro\"], tpr_white[\"micro\"], _ = roc_curve(y_white_onehot_test.ravel(), y_white_score.ravel())\n",
    "roc_auc_white[\"micro\"] = auc(fpr_white[\"micro\"], tpr_white[\"micro\"])\n",
    "\n",
    "print(f\"Micro-averaged One-vs-Rest ROC AUC score for white wine:\\n{roc_auc_white['micro']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035c58c-751c-4aa5-b766-1234db230eb3",
   "metadata": {},
   "source": [
    "### Computing the Macro-averaged One-vs-Rest ROC AUC score for white wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11edb60-6fa4-4625-bfa0-82cd79976ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    fpr_white[i], tpr_white[i], _ = roc_curve(y_red_onehot_test[:, i], y_score[:, i])\n",
    "    roc_auc_white[i] = auc(fpr_white[i], tpr_white[i])\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "# Interpolate all ROC curves at these points\n",
    "mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(fpr_grid, fpr_white[i], tpr_white[i])  # linear interpolation\n",
    "\n",
    "# Average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr_white[\"macro\"] = fpr_grid\n",
    "tpr_white[\"macro\"] = mean_tpr\n",
    "roc_auc_white[\"macro\"] = auc(fpr_white[\"macro\"], tpr_white[\"macro\"])\n",
    "\n",
    "print(f\"Macro-averaged One-vs-Rest ROC AUC score for white wine:\\n{roc_auc_white['macro']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32d910-5583-41aa-b4fc-dceb53df9b31",
   "metadata": {},
   "source": [
    "## Displaying ROC AUC's for DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc58455-8246-429a-8773-c77eabeeafb4",
   "metadata": {},
   "source": [
    "### Displaying ROC AUC's for each class in df_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebfbe2-ce0a-4851-999b-cdc0e7f3dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr_red[\"micro\"],\n",
    "    tpr_red[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc_red['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_red[\"macro\"],\n",
    "    tpr_red[\"macro\"],\n",
    "    label=f\"macro-average ROC curve (AUC = {roc_auc_red['macro']:.2f})\",\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = [\"red\", \"aqua\", \"darkorange\", \"cornflowerblue\", \"green\", \"lightgreen\"]\n",
    "\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_red_onehot_test[:, class_id],\n",
    "        y_red_score[:, class_id],\n",
    "        name=f\"ROC curve for quality {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Red Wine Quality (0-10)\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a481d-a21c-45a1-9980-e55ea5d8ee9a",
   "metadata": {},
   "source": [
    "### Displaying ROC AUC's for each class in df_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafbf485-c947-409f-acce-5e8853664d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr_red[\"micro\"],\n",
    "    tpr_red[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc_red['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr_red[\"macro\"],\n",
    "    tpr_red[\"macro\"],\n",
    "    label=f\"macro-average ROC curve (AUC = {roc_auc_red['macro']:.2f})\",\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_white_onehot_test[:, class_id],\n",
    "        y_white_score[:, class_id],\n",
    "        name=f\"ROC curve for quality {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"White Wine Quality (0-10)\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b4460-d288-475b-8af8-7dd5651e2632",
   "metadata": {},
   "source": [
    "## Confusion Matricies for DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e276c-84f5-4220-a0d3-07f5353dcbff",
   "metadata": {},
   "source": [
    "### Confusion Matricies for df_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb841d-30fc-45aa-976b-c8980d81f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "confusion_matricies_red = multilabel_confusion_matrix(y_red_test, yhat_red, labels=target_names)\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(25, 15))\n",
    "axes = axes.ravel()\n",
    "for i in range(n_classes):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matricies_red[i],\n",
    "                                  display_labels=[0, i])\n",
    "    disp.plot(ax=axes[i], values_format='.4g')\n",
    "    disp.ax_.set_title(f'Quality {target_names[i]}')\n",
    "    if i<10:\n",
    "        disp.ax_.set_xlabel('')\n",
    "    if i%5!=0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "    disp.im_.colorbar.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.10, hspace=0.10)\n",
    "f.colorbar(disp.im_, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204bf4c7-fd43-4b8e-87f9-36a844d2f72a",
   "metadata": {},
   "source": [
    "### Confusion Matricies for df_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf21d83-31f0-403b-8ecc-207f2a9726a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matricies_white = multilabel_confusion_matrix(y_white_test, yhat_white, labels=target_names)\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(25, 15))\n",
    "axes = axes.ravel()\n",
    "for i in range(n_classes):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matricies_white[i],\n",
    "                                  display_labels=[0, i])\n",
    "    disp.plot(ax=axes[i], values_format='.4g')\n",
    "    disp.ax_.set_title(f'Quality {target_names[i]}')\n",
    "    if i<10:\n",
    "        disp.ax_.set_xlabel('')\n",
    "    if i%5!=0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "    disp.im_.colorbar.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.10, hspace=0.10)\n",
    "f.colorbar(disp.im_, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b5292-b52e-4406-ac3d-7d4025d28104",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247b97bc-a2bb-40a4-b84b-aa3f7bfce7b1",
   "metadata": {},
   "source": [
    "Problem:\n",
    "We will be creating a multinomial logistic regession model to predict wine quality (red and white variants of the Portuguese \"Vinho Verde\" wine) based on physicochemical tests.\n",
    "\n",
    "We wrote a program that split the wine dataset into two smaller sets, each for red wine and white wine. We analyzed the data to find which transformers would best apply to the data. Since the data wasn't normally distributed, we tried applying several different transformers - such has PowerTransformer, MaxAbsScaler, StandardScaler, and MinMaxScaler - to see which one would best normalize the data. We discovered that the QuantileTransformer worked the best. We needed to apply OneHot encoding to the y_test data for both red and white data, through LabelEncoders that were fit to their corrosponding y_train data. Once we completed this, we made 2 seperate multinomial logistic regression models (one for each dataset) that told us the relationship between the quality of red and white wine to their physiochemical tests. Based on the results from our model, the quality of red wine has a closer association to its physiochemical tests than white wine does. For the red wine dataset the AUC scores for qualities 5, 6, 7, 4, 8, 3 were 0.77, 0.66, 0.78, 0.56, 0.90, and 0.92. For the white wine dataset the AUC scores for qualities 5, 6, 7, 4, 8, 3 were 0.19, 0.71, 0.76, 0.60, 0.76, and 0.76. The red wine datasets higher AUC scores show that the model had better accuracy predicting its quality as opposed to the white wine. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
